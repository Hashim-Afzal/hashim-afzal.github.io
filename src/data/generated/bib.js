define({ entries : {
    "10.3389/fnins.2020.00637": {
        "abstract": "<p>Hand gestures are a form of non-verbal communication used by individuals in conjunction with speech to communicate. Nowadays, with the increasing use of technology, hand-gesture recognition is considered to be an important aspect of Human-Machine Interaction (HMI), allowing the machine to capture and interpret the user's intent and to respond accordingly. The ability to discriminate between human gestures can help in several applications, such as assisted living, healthcare, neuro-rehabilitation, and sports. Recently, multi-sensor data fusion mechanisms have been investigated to improve discrimination accuracy. In this paper, we present a sensor fusion framework that integrates complementary systems: the electromyography (EMG) signal from muscles and visual information. This multi-sensor approach, while improving accuracy and robustness, introduces the disadvantage of high computational cost, which grows exponentially with the number of sensors and the number of measurements. Furthermore, this huge amount of data to process can affect the classification latency which can be crucial in real-case scenarios, such as prosthetic control. Neuromorphic technologies can be deployed to overcome these limitations since they allow real-time processing in parallel at low power consumption. In this paper, we present a fully neuromorphic sensor fusion approach for hand-gesture recognition comprised of an event-based vision sensor and three different neuromorphic processors. In particular, we used the event-based camera, called DVS, and two neuromorphic platforms, Loihi and ODIN + MorphIC. The EMG signals were recorded using traditional electrodes and then converted into spikes to be fed into the chips. We collected a dataset of five gestures from sign language where visual and electromyography signals are synchronized. We compared a fully neuromorphic approach to a baseline implemented using traditional machine learning approaches on a portable GPU system. According to the chip's constraints, we designed specific spiking neural networks (SNNs) for sensor fusion that showed classification accuracy comparable to the software baseline. These neuromorphic alternatives have increased inference time, between 20 and 40%, with respect to the GPU system but have a significantly smaller energy-delay product (EDP) which makes them between 30\u00d7 and 600\u00d7 more efficient. The proposed work represents a new benchmark that moves neuromorphic computing toward a real-world scenario.</p>",
        "author": "Ceolini, Enea  and Frenkel, Charlotte  and Shrestha, Sumit Bam  and Taverni, Gemma  and Khacef, Lyes  and Payvand, Melika  and Donati, Elisa",
        "doi": "10.3389/fnins.2020.00637",
        "issn": "1662-453X",
        "journal": "Frontiers in Neuroscience",
        "keywords": "low cost semg, standard camera, pose",
        "series": "",
        "title": "Hand-Gesture Recognition Based on EMG and Event-Based Camera Sensor Fusion: A Benchmark in Neuromorphic Computing",
        "type": "article",
        "url": "https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2020.00637",
        "volume": "14",
        "year": "2020"
    },
    "Brunelli2015-il": {
        "abstract": "Prosthetic hand control based on the acquisition and processing of surface electromyography signals (sEMG) is a well-established method that makes use of the electric potentials evoked by the physiological contraction processes of one or more muscles. Furthermore intelligent mobile medical devices are on the brink of introducing safe and highly sophisticated systems to help a broad patient community to regain a considerable amount of life quality. The major challenges which are inherent in such integrated system\u2019s design are mainly to be found in obtaining a compact system with a long mobile autonomy, capable of delivering the required signal requirements for EMG based prosthetic control with up to 32 simultaneous acquisition channels and \u2013 with an eye on a possible future exploitation as a medical device \u2013 a proper perspective on a low priced system. Therefore, according to these requirements we present a wireless, mobile platform for acquisition and communication of sEMG signals embedded into a complete mobile control system structure. This environment further includes a portable device such as a laptop providing the necessary computational power for the control and a commercially available robotic hand- prosthesis. Means of communication among those devices are based on the Bluetooth standard. We show, that the developed low cost mobile device can be used for proper prosthesis control and that the device can rely on a continuous operation for the usual daily life usage of a patient.",
        "author": "Brunelli, Davide and Tadesse, Andualem Maereg and Vodermayer, Bernhard and Nowak, Markus and Castellini, Claudio",
        "booktitle": "2015 6th International Workshop on Advances in Sensors and Interfaces ({IWASI})",
        "conference": "2015 6th IEEE International Workshop on Advances in Sensors and Interfaces (IWASI)",
        "doi": "10.1109/IWASI.2015.7184964",
        "keywords": "low cost semg, movement",
        "location": "Gallipoli",
        "month": "jun",
        "publisher": "IEEE",
        "series": "",
        "title": "Low-cost wearable multichannel surface {EMG} acquisition for prosthetic hand control",
        "type": "inproceedings",
        "year": "2015"
    },
    "Gomez-Correa2022-ky": {
        "abstract": "Surface electromyography (sEMG) is a non-invasive measure of electrical activity generated due to muscle contraction. In recent years, sEMG signals have been increasingly used in diverse applications such as rehabilitation, pattern recognition, and control of orthotic and prosthetic systems. This study presents the development of a versatile multi-channel sEMG low-cost wearable band system to acquire 4 signals. In this case, the signals acquired with the proposed device have been used to detect hand movements. However, the WyoFlex band could be used in some sections of the arm or the leg if the section's diameter matches the diameter of the WyoFlex band. The designed WyoFlex band was fabricated using three-dimensional (3D) printing techniques employing thermoplastic polyurethane and polylactic acid as manufacturing materials. Then, the proposed wearable electromyographic system (WES) consists of 2 WyoFlex bands, which simultaneously allow the wireless acquisition of 4 sEMG channels of each forearm. The collected sEMG can be visualized and stored for future post-processing stages using a graphical user interface designed in Node-RED. Several experimental tests were conducted to verify the performance of the WES. A dataset with sEMG collected from 15 healthy humans has been obtained as part of the presented results. In addition, a classification algorithm based on artificial neural networks has been implemented to validate the usability of the collected sEMG signals.",
        "author": "Gomez-Correa, Manuela and Cruz-Ortiz, David",
        "doi": "10.3390/s22165931",
        "journal": "Sensors (Basel)",
        "keywords": "artificial neural networks; multichannel system; surface electromyography; wearable armband; wireless communication, low cost semg, movement",
        "language": "en",
        "month": "aug",
        "number": "16",
        "series": "",
        "title": "Low-cost wearable band sensors of surface electromyography for detecting hand movements",
        "type": "article",
        "volume": "22",
        "year": "2022"
    },
    "Hu2019-oj": {
        "abstract": "To improve the accuracy of surface electromyography (sEMG)-based gesture recognition, we present a novel hybrid approach that combines real sEMG signals with corresponding virtual hand poses. The virtual hand poses are generated by means of a proposed cross-modal association model constructed based on the adversarial learning to capture the intrinsic relationship between the sEMG signals and the hand poses. We report comprehensive evaluations of the proposed approach for both frame- and window-based sEMG gesture recognitions on seven-sparse-multichannel and four-high-density-benchmark databases. The experimental results show that the proposed approach achieves significant improvements in sEMG-based gesture recognition compared to existing works. For frame-based sEMG gesture recognition, the recognition accuracy of the proposed framework is increased by an average of +5.2% on the sparse multichannel sEMG databases and by an average of +6.7% on the high-density sEMG databases compared to the existing methods. For window-based sEMG gesture recognition, the state-of-the-art recognition accuracies on three of the high-density sEMG databases are already higher than 99%, i.e., almost saturated; nevertheless, we achieve a +0.2% improvement. For the remaining eight sEMG databases, the average improvement with the proposed framework for the window-based approach is +2.5%.",
        "author": "Hu, Yu and Wong, Yongkang and Dai, Qingfeng and Kankanhalli, Mohan and Geng, Weidong and Li, Xiangdong",
        "doi": "10.1109/ACCESS.2019.2930005",
        "journal": "IEEE Access",
        "keywords": "standard semg, pose",
        "pages": "104108--104120",
        "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
        "series": "",
        "title": "{SEMG-based} gesture recognition with embedded virtual hand poses and adversarial learning",
        "type": "article",
        "volume": "7",
        "year": "2019"
    },
    "Liu2021-jk": {
        "abstract": "Ubiquitous finger motion tracking enables a number of exciting applications in augmented reality, sports analytics, rehabilitation-healthcare, haptics etc. This paper presents NeuroPose, a system that shows the feasibility of 3D finger motion tracking using a platform of wearable ElectroMyoGraphy (EMG) sensors. EMG sensors can sense electrical potential from muscles due to finger activation, thus offering rich information for fine-grained finger motion sensing. However converting the sensor information to 3D finger poses is non trivial since signals from multiple fingers superimpose at the sensor in complex patterns. Towards solving this problem, NeuroPose fuses information from anatomical constraints of finger motion with machine learning architectures on Recurrent Neural Networks (RNN), Encoder-Decoder Networks, and ResNets to extract 3D finger motion from noisy EMG data. The generated motion pattern is temporally smooth as well as anatomically consistent. Furthermore, a transfer learning algorithm is leveraged to adapt a pretrained model on one user to a new user with minimal training overhead. A systematic study with 12 users demonstrates a median error of 6.24\u00b0 and a 90%-ile error of 18.33\u00b0 in tracking 3D finger joint angles. The accuracy is robust to natural variation in sensor mounting positions as well as changes in wrist positions of the user. NeuroPose is implemented on a smartphone with a processing latency of 0.101s, and a low energy overhead.",
        "address": "New York, NY, USA",
        "author": "Liu, Yilin and Zhang, Shijia and Gowda, Mahanth",
        "booktitle": "Proceedings of the Web Conference 2021",
        "conference": "WWW '21: The Web Conference 2021",
        "doi": "10.1145/3442381.3449890",
        "keywords": "pose, low cost semg",
        "location": "Ljubljana Slovenia",
        "month": "apr",
        "publisher": "ACM",
        "series": "",
        "title": "{NeuroPose}: {3D} Hand Pose Tracking using {EMG} Wearables",
        "type": "inproceedings",
        "year": "2021"
    },
    "Liu2021-wv": {
        "abstract": "This paper presents WR-Hand, a wearable-based system tracking 3D hand pose of 14 hand skeleton points over time using Electromyography (EMG) and gyroscope sensor data from commercial armband. This system provides a significant leap in wearable sensing and enables new application potentials in medical care, human-computer interaction, etc. A challenge is the armband EMG sensors inevitably collect mixed EMG signals from multiple forearm muscles because of the fixed sensor positions on the device, while prior bio-medical models for hand pose tracking are built on isolated EMG signal inputs from isolated forearm spots for different muscles. In this paper, we leverage the recent success of neural networks to enhance the existing bio-medical model using the armband's EMG data and visualize our design to understand why our solution is effective. Moreover, we propose solutions to place the constructed hand pose reliably in a global coordinate system, and address two practical issues by providing a general plug-and-play version for new users without training and compensating for the position difference in how users wear their armbands. We implement a prototype using different commercial armbands, which is lightweight to execute on user's phone in real-time. Extensive evaluation shows the efficacy of the WR-Hand design.",
        "author": "Liu, Yang and Lin, Chengdong and Li, Zhenjiang",
        "doi": "10.1145/3478112",
        "journal": "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.",
        "keywords": "low cost semg, pose",
        "language": "en",
        "month": "sep",
        "number": "3",
        "pages": "1--27",
        "publisher": "Association for Computing Machinery (ACM)",
        "series": "",
        "title": "{WR-hand}",
        "type": "article",
        "volume": "5",
        "year": "2021"
    },
    "Mora2024-kh": {
        "abstract": "The design and control of artificial hands remains a challenge in engineering. Popular prostheses are bio-mechanically simple with restricted manipulation capabilities, as advanced devices are pricy or abandoned due to their difficult communication with the hand. For social robots, the interpretation of human intention is key for their integration in daily life. This can be achieved with machine learning (ML) algorithms, which are barely used for grasping posture recognition. This work proposes an ML approach to recognize nine hand postures, representing 90\\% of the activities of daily living in real time using an sEMG human-robot interface (HRI). Data from 20 subjects wearing a Myo armband (8 sEMG signals) were gathered from the NinaPro DS5 and from experimental tests with the YCB Object Set, and they were used jointly in the development of a simple multi-layer perceptron in MATLAB, with a global percentage success of 73\\% using only two features. GPU-based implementations were run to select the best architecture, with generalization capabilities, robustness-versus-electrode shift, low memory expense, and real-time performance. This architecture enables the implementation of grasping posture recognition in low-cost devices, aimed at the development of affordable functional prostheses and HRI for social robots.",
        "author": "Mora, Marta C and Garc{\\'\\i}a-Ortiz, Jos{\\'e} V and Cerd{\\'a}-Boluda, Joaqu{\\'\\i}n",
        "doi": "10.3390/s24072063",
        "journal": "Sensors (Basel)",
        "keywords": "EMG; HRI; artificial hand; grasping postures; low-cost devices; machine learning; recognition, low cost semg, pose",
        "language": "en",
        "month": "mar",
        "number": "7",
        "series": "",
        "title": "{SEMG-based} robust recognition of grasping postures with a machine learning approach for low-cost hand control",
        "type": "article",
        "volume": "24",
        "year": "2024"
    },
    "Nasri2019-rs": {
        "abstract": "Every year, a significant number of people lose a body part in an accident, through sickness or in high-risk manual jobs. Several studies and research works have tried to reduce the constraints and risks in their lives through the use of technology. This work proposes a learning-based approach that performs gesture recognition using a surface electromyography-based device, the Myo Armband released by Thalmic Labs, which is a commercial device and has eight non-intrusive low-cost sensors. With 35 able-bodied subjects, and using the Myo Armband device, which is able to record data at about 200 MHz, we collected a dataset that includes six dissimilar hand gestures. We used a gated recurrent unit network to train a system that, as input, takes raw signals extracted from the surface electromyography sensors. The proposed approach obtained a 99.90\\% training accuracy and 99.75\\% validation accuracy. We also evaluated the proposed system on a test set (new subjects) obtaining an accuracy of 77.85\\%. In addition, we showed the test prediction results for each gesture separately and analyzed which gestures for the Myo armband with our suggested network can be difficult to distinguish accurately. Moreover, we studied for first time the gated recurrent unit network capability in gesture recognition approaches. Finally, we integrated our method in a system that is able to classify live hand gestures.",
        "author": "Nasri, Nadia and Orts-Escolano, Sergio and Gomez-Donoso, Francisco and Cazorla, Miguel",
        "doi": "",
        "journal": "Sensors (Basel)",
        "keywords": "dataset; gated recurrent units; gesture recognition; surface electromyography sensor, low cost semg, pose",
        "language": "en",
        "month": "jan",
        "number": "2",
        "pages": "371",
        "publisher": "MDPI AG",
        "series": "",
        "title": "Inferring static hand poses from a low-cost non-intrusive {sEMG sensor",
        "type": "article",
        "volume": "19",
        "year": "2019"
    },
    "Sun2018-li": {
        "abstract": "A weighted fusion method of D-S evidence theory in decision making is proposed to aim at the problem of lacking in the distribution of trust, data processing and precision in D-S evidential theory. The method of gesture recognition based on Kinect and sEMG signal are established. Weighted D-S evidence theory is used to fuse Kinect and sEMG signals and the simulation experiment is made respectively. The stimulation results show that comparing with other experimental methods, the decision fusion method based on weighted D-S evidence theory has higher utilization efficiency and recognition rate",
        "author": "Sun, Ying and Li, Cuiqiao and Li, Gongfa and Jiang, Guozhang and Jiang, Du and Liu, Honghai and Zheng, Zhigao and Shu, Wanneng",
        "doi": "10.1007/s11036-018-1008-0",
        "journal": "Mob. Netw. Appl.",
        "keywords": "pose, standard semg, low cost camera",
        "language": "en",
        "month": "aug",
        "number": "4",
        "pages": "797--805",
        "publisher": "Springer Nature",
        "series": "",
        "title": "Gesture recognition based on Kinect and {sEMG} signal fusion",
        "type": "article",
        "volume": "23",
        "year": "2018"
    },
    "Zhong2021-jv": {
        "abstract": "Surface electromyogram (sEMG) signals have been used in human motion intention recognition, which has significant application prospects in the fields of rehabilitation medicine and cognitive science. However, some valuable dynamic information on upper-limb motions is lost in the process of feature extraction for sEMG signals, and there exists the fact that only a small variety of rehabilitation movements can be distinguished, and the classification accuracy is easily affected. To solve these dilemmas, first, a multiscale time-frequency information fusion representation method (MTFIFR) is proposed to obtain the time-frequency features of multichannel sEMG signals. Then, this paper designs the multiple feature fusion network (MFFN), which aims at strengthening the ability of feature extraction. Finally, a deep belief network (DBN) was introduced as the classification model of the MFFN to boost the generalization performance for more types of upper-limb movements. In the experiments, 12 kinds of upper-limb rehabilitation actions were recognized utilizing four sEMG sensors. The maximum identification accuracy was 86.10\\% and the average classification accuracy of the proposed MFFN was 73.49\\%, indicating that the time-frequency representation approach combined with the MFFN is superior to the traditional machine learning and convolutional neural network.",
        "author": "Zhong, Tianyang and Li, Donglin and Wang, Jianhui and Xu, Jiacan and An, Zida and Zhu, Yue",
        "copyright": "https://creativecommons.org/licenses/by/4.0/",
        "doi": "10.3390/s21165385",
        "journal": "Sensors (Basel)",
        "keywords": "deep belief network; motion intention recognition; multiple feature fusion network; multiscale time-frequency information fusion representation; surface electromyogram, standard semg, movement",
        "language": "en",
        "month": "aug",
        "number": "16",
        "pages": "5385",
        "publisher": "MDPI AG",
        "series": "",
        "title": "Fusion learning for {sEMG} recognition of multiple upper-limb rehabilitation movements",
        "type": "article",
        "volume": "21",
        "year": "2021"
    }
}});